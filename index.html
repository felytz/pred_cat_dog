<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Perros y Gatos</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet">
  <style>
    #resultado {
      font-weight: bold;
      font-size: 6rem;
      text-align: center;
      min-height: 8rem;
    }
    #model-info {
      font-size: 1rem;
      background: #f8f9fa;
      padding: 10px;
      border-radius: 5px;
      margin: 10px 0;
    }
    #confidence-bar {
      height: 20px;
      background: #e9ecef;
      margin: 10px 0;
      border-radius: 10px;
      overflow: hidden;
    }
    #confidence-progress {
      height: 100%;
      background: linear-gradient(90deg, #ff6b6b, #4ecdc4);
      width: 50%;
      transition: width 0.3s;
    }
    .model-active {
      box-shadow: 0 0 0 3px rgba(13, 110, 253, 0.5);
    }
    #camera-select {
      margin-bottom: 10px;
    }
  </style>
</head>
<body>
  <main>
    <div class="px-4 py-2 my-2 text-center border-bottom">
      <h1 class="display-5 fw-bold">Perros y Gatos</h1>
      <div class="col-lg-6 mx-auto">
        <p class="lead mb-0">Clasificaci칩n en tiempo real con TensorFlow.js</p>
      </div>
    </div>

    <div class="container mt-4">
      <div class="row justify-content-center">
        <div class="col-12 col-md-6 text-center">
          <!-- Camera Feed -->
          <div class="position-relative mb-3">
            <canvas id="canvas" width="400" height="400" class="img-fluid border rounded"></canvas>
            <canvas id="processing-canvas" width="100" height="100" style="display: none;"></canvas>
            <div class="position-absolute top-0 start-0 m-2">
              <span id="facing-mode" class="badge bg-secondary">C치mara</span>
            </div>
          </div>
          
          <!-- Model Selection -->
          <div class="d-flex justify-content-center gap-2 mb-3">
            <button id="btn-dense" class="btn btn-primary model-btn">Modelo Dense</button>
            <button id="btn-cnn" class="btn btn-outline-primary model-btn">Modelo CNN</button>
          </div>
          
          <!-- Prediction Output -->
          <div id="model-info" class="text-start">
            <div>Modelo cargado: <span id="model-name">Dense</span></div>
            <div>Precisi칩n: <span id="confidence-value">0%</span></div>
            <div id="confidence-bar"><div id="confidence-progress"></div></div>
          </div>
          
          <div id="resultado" class="my-3"></div>
          
          <!-- Controls -->
          <div class="d-flex justify-content-center gap-2">
            <button id="switch-camera" class="btn btn-secondary">Cambiar C치mara</button>
          </div>
        </div>
      </div>
    </div>
  </main>

  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.5.0/dist/tf.min.js"></script>
  
  <script>
    // App State with prediction history
    const state = {
      currentModel: 'dense',
      models: {
        dense: null,
        cnn: null
      },
      stream: null,
      facingMode: 'environment',
      isModelLoading: false,
      predictionHistory: [], // Stores {timestamp, value} pairs
      lastUpdateTime: 0,
      currentAverage: 0.5 // Initial neutral value
    };

    // DOM Elements
    const elements = {
      canvas: document.getElementById('canvas'),
      processingCanvas: document.getElementById('processing-canvas'),
      result: document.getElementById('resultado'),
      modelName: document.getElementById('model-name'),
      confidenceValue: document.getElementById('confidence-value'),
      confidenceBar: document.getElementById('confidence-progress'),
      btnDense: document.getElementById('btn-dense'),
      btnCnn: document.getElementById('btn-cnn'),
      switchCamera: document.getElementById('switch-camera')
    };

    // Initialize
    document.addEventListener('DOMContentLoaded', async () => {
      try {
        // Load models
        await loadModel('dense');
        await loadModel('cnn');
        
        // Setup camera
        await setupCamera();
        
        // Start prediction loop
        predict();
        
        // Setup event listeners
        setupEventListeners();
        
      } catch (error) {
        console.error("Initialization error:", error);
        elements.result.textContent = `Error: ${error.message}`;
      }
    });

    // Model Loading
    async function loadModel(modelName) {
      const modelPath = `${modelName}_tfjs_model/model.json`;
      
      try {
        console.log(`Loading ${modelName} model from: ${modelPath}`);
        state.models[modelName] = await tf.loadGraphModel(modelPath);
        console.log(`${modelName} model loaded successfully`);
      } catch (error) {
        console.error(`Error loading ${modelName} model:`, error);
        throw new Error(`Failed to load ${modelName} model`);
      }
    }

    // Camera Setup
    async function setupCamera() {
      if (state.stream) {
        state.stream.getTracks().forEach(track => track.stop());
      }

      const constraints = {
        video: {
          width: { ideal: 400 },
          height: { ideal: 400 },
          facingMode: state.facingMode
        }
      };

      try {
        state.stream = await navigator.mediaDevices.getUserMedia(constraints);
        const video = document.createElement('video');
        video.srcObject = state.stream;
        video.autoplay = true;
        
        video.onloadedmetadata = () => {
          const ctx = elements.canvas.getContext('2d');
          const processingCtx = elements.processingCanvas.getContext('2d');
          
          function draw() {
            if (video.readyState >= 2) {
              ctx.drawImage(video, 0, 0, elements.canvas.width, elements.canvas.height);
              processingCtx.drawImage(video, 0, 0, 100, 100);
            }
            requestAnimationFrame(draw);
          }
          
          video.play();
          draw();
        };
      } catch (error) {
        console.error("Camera error:", error);
        throw new Error("No se pudo acceder a la c치mara");
      }
    }

    // Image Processing
    function prepareImage() {
      return tf.tidy(() => {
        return tf.browser.fromPixels(elements.processingCanvas)
          .resizeNearestNeighbor([100, 100])
          .mean(2)
          .expandDims(2)
          .expandDims()
          .toFloat()
          .div(255.0);
      });
    }

      // Prediction with Smoothing
      async function predict() {
        if (!state.models[state.currentModel]) {
          requestAnimationFrame(predict);
          return;
        }

        try {
          // 1. Get current prediction
          const inputTensor = prepareImage();
          const prediction = await state.models[state.currentModel].predict(inputTensor).data();
          const currentValue = prediction[0];
          inputTensor.dispose();

          // 2. Store prediction with timestamp
          const now = Date.now();
          state.predictionHistory.push({
            timestamp: now,
            value: currentValue
          });

          // 3. Remove predictions older than 2 seconds
          state.predictionHistory = state.predictionHistory.filter(
            entry => now - entry.timestamp < 2000
          );

          // 4. Calculate moving average if we have enough data
          if (state.predictionHistory.length > 0) {
            const sum = state.predictionHistory.reduce((acc, entry) => acc + entry.value, 0);
            state.currentAverage = sum / state.predictionHistory.length;
          }

          // 5. Only update UI at most 10 times per second (optional)
          const nowMs = Date.now();
          if (nowMs - state.lastUpdateTime > 100) {
            updateUI(state.currentAverage * 100);
            state.lastUpdateTime = nowMs;
          }

        } catch (error) {
          console.error("Prediction error:", error);
        } finally {
          requestAnimationFrame(predict);
        }
      }

    // Update UI
    function updateUI(confidence) {
      const isDog = confidence > 50;
      elements.result.textContent = isDog ? "游냤 Perro" : "游냠 Gato";
      elements.confidenceValue.textContent = `${confidence.toFixed(1)}%`;
      elements.confidenceBar.style.width = `${confidence}%`;
      elements.confidenceBar.style.background = isDog 
        ? `linear-gradient(90deg, #4ecdc4, #4ecdc4)` 
        : `linear-gradient(90deg, #ff6b6b, #ff6b6b)`;
    }

    // Switch Model
    async function switchModel(newModel) {
      if (state.currentModel === newModel || state.isModelLoading) return;
      
      state.isModelLoading = true;
      elements.result.textContent = "Cargando modelo...";
      
      try {
        state.currentModel = newModel;
        elements.modelName.textContent = newModel === 'dense' ? 'Dense' : 'CNN';
        
        // Update button states
        elements.btnDense.classList.toggle('btn-primary', newModel === 'dense');
        elements.btnDense.classList.toggle('btn-outline-primary', newModel !== 'dense');
        elements.btnCnn.classList.toggle('btn-primary', newModel === 'cnn');
        elements.btnCnn.classList.toggle('btn-outline-primary', newModel !== 'cnn');
        
      } catch (error) {
        console.error("Error switching model:", error);
      } finally {
        state.isModelLoading = false;
      }
    }

    // Switch Camera
    async function toggleCamera() {
      state.facingMode = state.facingMode === 'user' ? 'environment' : 'user';
      await setupCamera();
    }

    // Event Listeners
    function setupEventListeners() {
      elements.btnDense.addEventListener('click', () => switchModel('dense'));
      elements.btnCnn.addEventListener('click', () => switchModel('cnn'));
      elements.switchCamera.addEventListener('click', toggleCamera);
    }
  </script>
</body>
</html>